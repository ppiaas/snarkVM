//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30794723
// Cuda compilation tools, release 11.6, V11.6.55
// Based on NVVM 7.0.1
//

.version 7.6
.target sm_52
.address_size 64

	// .globl	msm6_pixel
.extern .func _Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine
(
	.param .b64 _Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine_param_0,
	.param .b64 _Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine_param_1,
	.param .b64 _Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine_param_2
)
;
.extern .func _Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_
(
	.param .b64 _Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2__param_0,
	.param .b64 _Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2__param_1,
	.param .b64 _Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2__param_2
)
;
.global .align 8 .b8 __nv_static_27__1d7d5d67_6_msm_cu_caa854b9_BLS12_377_P[48] = {1, 0, 0, 0, 0, 192, 8, 133, 0, 0, 0, 48, 68, 93, 11, 23, 0, 72, 9, 186, 47, 98, 243, 30, 143, 19, 245, 0, 243, 217, 34, 26, 59, 73, 161, 108, 192, 5, 59, 198, 234, 16, 197, 23, 70, 58, 174, 1};
.global .align 8 .b8 __nv_static_27__1d7d5d67_6_msm_cu_caa854b9_BLS12_377_ZERO[48];
.global .align 8 .b8 __nv_static_27__1d7d5d67_6_msm_cu_caa854b9_BLS12_377_ONE[48] = {104, 255, 255, 255, 255, 255, 205, 2, 177, 255, 255, 127, 131, 159, 64, 81, 242, 63, 125, 138, 169, 179, 125, 159, 5, 99, 124, 110, 183, 151, 78, 123, 232, 132, 60, 128, 191, 149, 244, 76, 154, 244, 253, 226, 97, 102, 141, 0};
.global .align 8 .b8 __nv_static_27__1d7d5d67_6_msm_cu_caa854b9_BLS12_377_R2[48] = {34, 205, 0, 148, 108, 104, 134, 183, 177, 49, 4, 176, 170, 252, 41, 3, 109, 180, 214, 98, 17, 241, 165, 34, 172, 195, 125, 130, 3, 125, 223, 191, 249, 11, 121, 65, 240, 146, 126, 131, 136, 75, 145, 30, 203, 252, 109, 0};
.global .align 8 .u64 __nv_static_27__1d7d5d67_6_msm_cu_caa854b9_BLS12_377_p0 = -8860621160618917889;
.extern .global .align 8 .b8 BLS12_377_ZERO_PROJECTIVE[144];

.visible .entry msm6_pixel(
	.param .u64 msm6_pixel_param_0,
	.param .u64 msm6_pixel_param_1,
	.param .u64 msm6_pixel_param_2,
	.param .u64 msm6_pixel_param_3,
	.param .u32 msm6_pixel_param_4
)
{
	.local .align 16 .b8 	__local_depot0[4240];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<92>;
	.reg .b64 	%rd<97>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd23, [msm6_pixel_param_0];
	ld.param.u64 	%rd21, [msm6_pixel_param_1];
	ld.param.u64 	%rd24, [msm6_pixel_param_2];
	ld.param.u64 	%rd25, [msm6_pixel_param_3];
	ld.param.u32 	%r45, [msm6_pixel_param_4];
	cvta.to.global.u64 	%rd1, %rd24;
	cvta.to.global.u64 	%rd2, %rd23;
	cvta.to.global.u64 	%rd3, %rd25;
	add.u64 	%rd26, %SP, 0;
	add.u64 	%rd4, %SPL, 0;
	add.u64 	%rd5, %SPL, 144;
	mov.u32 	%r1, %tid.x;
	shr.u32 	%r47, %r1, 6;
	cvt.u64.u32 	%rd6, %r47;
	cvt.u64.u32 	%rd28, %r1;
	and.b32  	%r48, %r1, -64;
	cvt.u64.u32 	%rd29, %r48;
	sub.s64 	%rd30, %rd28, %rd29;
	cvt.u32.u64 	%r49, %rd30;
	mov.u64 	%rd31, 1;
	shl.b64 	%rd7, %rd31, %r49;
	mov.u32 	%r72, 0;
	mov.u64 	%rd92, BLS12_377_ZERO_PROJECTIVE;
	mov.u64 	%rd93, %rd4;

$L__BB0_1:
	ld.global.v2.u32 	{%r50, %r51}, [%rd92];
	st.local.v2.u32 	[%rd93], {%r50, %r51};
	add.s64 	%rd93, %rd93, 8;
	add.s64 	%rd92, %rd92, 8;
	add.s32 	%r72, %r72, 1;
	setp.lt.u32 	%p1, %r72, 18;
	@%p1 bra 	$L__BB0_1;

	mov.u32 	%r4, %ctaid.x;
	shl.b32 	%r81, %r4, 10;
	mul.wide.u32 	%rd32, %r4, 4;
	add.s64 	%rd33, %rd3, %rd32;
	ld.global.u32 	%r6, [%rd33];
	add.s32 	%r55, %r6, %r81;
	setp.ge.u32 	%p2, %r81, %r55;
	mov.u32 	%r76, 0;
	@%p2 bra 	$L__BB0_19;

	add.s32 	%r58, %r6, -1;
	and.b32  	%r85, %r6, 3;
	setp.lt.u32 	%p3, %r58, 3;
	mov.u32 	%r76, 0;
	@%p3 bra 	$L__BB0_14;

	sub.s32 	%r73, %r85, %r6;
	shl.b64 	%rd36, %rd6, 3;

$L__BB0_5:
	mul.wide.u32 	%rd34, %r81, 32;
	add.s64 	%rd35, %rd1, %rd34;
	add.s64 	%rd37, %rd35, %rd36;
	ld.global.u64 	%rd38, [%rd37];
	and.b64  	%rd39, %rd38, %rd7;
	setp.eq.s64 	%p4, %rd39, 0;
	@%p4 bra 	$L__BB0_7;

	add.s32 	%r12, %r76, 1;
	mul.wide.u32 	%rd40, %r76, 4;
	add.s64 	%rd41, %rd5, %rd40;
	st.local.u32 	[%rd41], %r81;
	mov.u32 	%r76, %r12;

$L__BB0_7:
	add.s32 	%r14, %r81, 1;
	mul.wide.u32 	%rd42, %r14, 32;
	add.s64 	%rd43, %rd1, %rd42;
	add.s64 	%rd45, %rd43, %rd36;
	ld.global.u64 	%rd46, [%rd45];
	and.b64  	%rd47, %rd46, %rd7;
	setp.eq.s64 	%p5, %rd47, 0;
	@%p5 bra 	$L__BB0_9;

	add.s32 	%r15, %r76, 1;
	mul.wide.u32 	%rd48, %r76, 4;
	add.s64 	%rd49, %rd5, %rd48;
	add.s32 	%r69, %r81, 1;
	st.local.u32 	[%rd49], %r69;
	mov.u32 	%r76, %r15;

$L__BB0_9:
	add.s32 	%r17, %r81, 2;
	mul.wide.u32 	%rd50, %r17, 32;
	add.s64 	%rd51, %rd1, %rd50;
	add.s64 	%rd53, %rd51, %rd36;
	ld.global.u64 	%rd54, [%rd53];
	and.b64  	%rd55, %rd54, %rd7;
	setp.eq.s64 	%p6, %rd55, 0;
	@%p6 bra 	$L__BB0_11;

	add.s32 	%r18, %r76, 1;
	mul.wide.u32 	%rd56, %r76, 4;
	add.s64 	%rd57, %rd5, %rd56;
	add.s32 	%r70, %r81, 2;
	st.local.u32 	[%rd57], %r70;
	mov.u32 	%r76, %r18;

$L__BB0_11:
	add.s32 	%r20, %r81, 3;
	mul.wide.u32 	%rd58, %r20, 32;
	add.s64 	%rd59, %rd1, %rd58;
	add.s64 	%rd61, %rd59, %rd36;
	ld.global.u64 	%rd62, [%rd61];
	and.b64  	%rd63, %rd62, %rd7;
	setp.eq.s64 	%p7, %rd63, 0;
	@%p7 bra 	$L__BB0_13;

	add.s32 	%r21, %r76, 1;
	mul.wide.u32 	%rd64, %r76, 4;
	add.s64 	%rd65, %rd5, %rd64;
	add.s32 	%r71, %r81, 3;
	st.local.u32 	[%rd65], %r71;
	mov.u32 	%r76, %r21;

$L__BB0_13:
	add.s32 	%r81, %r81, 4;
	add.s32 	%r73, %r73, 4;
	setp.ne.s32 	%p8, %r73, 0;
	@%p8 bra 	$L__BB0_5;

$L__BB0_14:
	setp.eq.s32 	%p9, %r85, 0;
	@%p9 bra 	$L__BB0_19;

	mul.wide.u32 	%rd66, %r81, 32;
	add.s64 	%rd67, %rd1, %rd66;
	shl.b64 	%rd68, %rd6, 3;
	add.s64 	%rd94, %rd67, %rd68;

$L__BB0_16:
	.pragma "nounroll";
	ld.global.u64 	%rd69, [%rd94];
	and.b64  	%rd70, %rd69, %rd7;
	setp.eq.s64 	%p10, %rd70, 0;
	@%p10 bra 	$L__BB0_18;

	add.s32 	%r31, %r76, 1;
	mul.wide.u32 	%rd71, %r76, 4;
	add.s64 	%rd72, %rd5, %rd71;
	st.local.u32 	[%rd72], %r81;
	mov.u32 	%r76, %r31;

$L__BB0_18:
	add.s32 	%r81, %r81, 1;
	add.s64 	%rd94, %rd94, 32;
	add.s32 	%r85, %r85, -1;
	setp.ne.s32 	%p11, %r85, 0;
	@%p11 bra 	$L__BB0_16;

$L__BB0_19:
	setp.eq.s32 	%p12, %r76, 0;
	@%p12 bra 	$L__BB0_26;

	add.s32 	%r61, %r76, -1;
	and.b32  	%r91, %r76, 3;
	setp.lt.u32 	%p13, %r61, 3;
	mov.u32 	%r90, 0;
	@%p13 bra 	$L__BB0_23;

	sub.s32 	%r89, %r76, %r91;

$L__BB0_22:
	mul.wide.u32 	%rd73, %r90, 4;
	add.s64 	%rd74, %rd5, %rd73;
	ld.local.u32 	%r63, [%rd74];
	mul.wide.u32 	%rd75, %r63, 96;
	add.s64 	%rd76, %rd21, %rd75;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd26;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd76;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 0
	ld.local.u32 	%r64, [%rd74+4];
	mul.wide.u32 	%rd78, %r64, 96;
	add.s64 	%rd79, %rd21, %rd78;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd26;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd79;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 1
	ld.local.u32 	%r65, [%rd74+8];
	mul.wide.u32 	%rd80, %r65, 96;
	add.s64 	%rd81, %rd21, %rd80;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd26;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd81;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 2
	ld.local.u32 	%r66, [%rd74+12];
	mul.wide.u32 	%rd82, %r66, 96;
	add.s64 	%rd83, %rd21, %rd82;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd26;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd83;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 3
	add.s32 	%r90, %r90, 4;
	add.s32 	%r89, %r89, -4;
	setp.ne.s32 	%p14, %r89, 0;
	@%p14 bra 	$L__BB0_22;

$L__BB0_23:
	setp.eq.s32 	%p15, %r91, 0;
	@%p15 bra 	$L__BB0_26;

	mul.wide.u32 	%rd84, %r90, 4;
	add.s64 	%rd95, %rd5, %rd84;

$L__BB0_25:
	.pragma "nounroll";
	ld.local.u32 	%r67, [%rd95];
	mul.wide.u32 	%rd85, %r67, 96;
	add.s64 	%rd86, %rd21, %rd85;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd26;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd86;
	call.uni 
	_Z32blst_p1_add_affine_to_projectiveP7blst_p1PKS_PK14blst_p1_affine, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 4
	add.s64 	%rd95, %rd95, 4;
	add.s32 	%r91, %r91, -1;
	setp.ne.s32 	%p16, %r91, 0;
	@%p16 bra 	$L__BB0_25;

$L__BB0_26:
	mad.lo.s32 	%r68, %r1, %r45, %r4;
	mul.wide.u32 	%rd89, %r68, 144;
	add.s64 	%rd18, %rd2, %rd89;
	mov.u64 	%rd96, 0;

$L__BB0_27:
	add.s64 	%rd90, %rd4, %rd96;
	ld.local.u8 	%rs1, [%rd90];
	add.s64 	%rd91, %rd18, %rd96;
	st.global.u8 	[%rd91], %rs1;
	add.s64 	%rd96, %rd96, 1;
	setp.lt.u64 	%p17, %rd96, 144;
	@%p17 bra 	$L__BB0_27;

	ret;

}
	// .globl	msm6_collapse_rows
.visible .entry msm6_collapse_rows(
	.param .u64 msm6_collapse_rows_param_0,
	.param .u64 msm6_collapse_rows_param_1,
	.param .u32 msm6_collapse_rows_param_2
)
{
	.local .align 8 .b8 	__local_depot1[144];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<8>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<27>;
	.reg .b64 	%rd<35>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd11, [msm6_collapse_rows_param_0];
	ld.param.u64 	%rd9, [msm6_collapse_rows_param_1];
	ld.param.u32 	%r15, [msm6_collapse_rows_param_2];
	cvta.to.global.u64 	%rd12, %rd9;
	cvta.to.global.u64 	%rd1, %rd11;
	add.u64 	%rd13, %SP, 0;
	add.u64 	%rd2, %SPL, 0;
	mov.u32 	%r1, %tid.x;
	mul.lo.s32 	%r2, %r1, %r15;
	add.s32 	%r3, %r2, %r15;
	mul.wide.u32 	%rd14, %r2, 144;
	add.s64 	%rd3, %rd12, %rd14;
	mov.u64 	%rd33, 0;
	mov.u32 	%r22, 0;

$L__BB1_1:
	add.s64 	%rd15, %rd3, %rd33;
	ld.global.u8 	%rs1, [%rd15];
	add.s64 	%rd16, %rd2, %rd33;
	st.local.u8 	[%rd16], %rs1;
	add.s64 	%rd33, %rd33, 1;
	add.s32 	%r22, %r22, 1;
	setp.lt.u32 	%p1, %r22, 144;
	@%p1 bra 	$L__BB1_1;

	add.s32 	%r25, %r2, 1;
	setp.ge.u32 	%p2, %r25, %r3;
	@%p2 bra 	$L__BB1_9;

	add.s32 	%r17, %r15, -1;
	and.b32  	%r24, %r17, 3;
	setp.eq.s32 	%p3, %r24, 0;
	@%p3 bra 	$L__BB1_6;

$L__BB1_5:
	.pragma "nounroll";
	mul.wide.u32 	%rd17, %r25, 144;
	add.s64 	%rd18, %rd9, %rd17;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd13;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd18;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 5
	add.s32 	%r25, %r25, 1;
	add.s32 	%r24, %r24, -1;
	setp.ne.s32 	%p4, %r24, 0;
	@%p4 bra 	$L__BB1_5;

$L__BB1_6:
	add.s32 	%r18, %r15, -2;
	setp.lt.u32 	%p5, %r18, 3;
	@%p5 bra 	$L__BB1_9;

$L__BB1_8:
	mul.wide.u32 	%rd20, %r25, 144;
	add.s64 	%rd21, %rd9, %rd20;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd13;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd21;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 6
	add.s32 	%r19, %r25, 1;
	mul.wide.u32 	%rd23, %r19, 144;
	add.s64 	%rd24, %rd9, %rd23;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd13;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd24;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 7
	add.s32 	%r20, %r25, 2;
	mul.wide.u32 	%rd25, %r20, 144;
	add.s64 	%rd26, %rd9, %rd25;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd13;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd26;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 8
	add.s32 	%r21, %r25, 3;
	mul.wide.u32 	%rd27, %r21, 144;
	add.s64 	%rd28, %rd9, %rd27;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.b64 	[param0+0], %rd13;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd13;
	.param .b64 param2;
	st.param.b64 	[param2+0], %rd28;
	call.uni 
	_Z36blst_p1_add_projective_to_projectiveP7blst_p1PKS_S2_, 
	(
	param0, 
	param1, 
	param2
	);
	} // callseq 9
	add.s32 	%r25, %r25, 4;
	setp.lt.u32 	%p6, %r25, %r3;
	@%p6 bra 	$L__BB1_8;

$L__BB1_9:
	mul.wide.u32 	%rd30, %r1, 144;
	add.s64 	%rd6, %rd1, %rd30;
	mov.u64 	%rd34, 0;

$L__BB1_10:
	add.s64 	%rd31, %rd2, %rd34;
	ld.local.u8 	%rs2, [%rd31];
	add.s64 	%rd32, %rd6, %rd34;
	st.global.u8 	[%rd32], %rs2;
	add.s64 	%rd34, %rd34, 1;
	setp.lt.u64 	%p7, %rd34, 144;
	@%p7 bra 	$L__BB1_10;

	ret;

}

